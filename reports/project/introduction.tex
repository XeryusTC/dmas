In modern times, a lot of information is spread out among many sources. One of
these sources is the internet, where a large collection of different entities
need to be able to communicate so that they can achieve their goals. Multi
agent systems do not differ much from this. Various agents with different
capabilities have to communicate and collaborate in order to achieve a common
goal. The domain where agents based systems are useful grows larger all the
time. This has resulted many applications based on multi agent systems as well
as many algorithms (with various uses) that come along with the agents
themselves. 

\subsection{Problem discription}
In this particular paper we are describing a situation where various robots
work together under a common coordinator. In our case that goal is to retrieve
people who have been trapped in a maze. To this end, many different situations
have to be taken into account for the smooth extraction of the victim, such as
robot collision avoidance, robot destruction or prioritization between targets.
Another major pitfall is the computation of all the data available. For a small
area, a regular desktop power machine would be sufficient, but for larger real
world applications it would not scale up properly because there are many
machines involved, including some physical robots. In that case the agents
should be able to outsource the computation to other agents which run on
hardware that is dedicated for computing the task.


\subsection{State of the Art}
We base our approach on the following two papers which describe the state of
the art for our domain. \cite{intframe}.

\subsection{New Idea}
The main procedure is as follows; first search robots are sent into the
uncharted maze. As they move around the immediate environment is sensed and
this information gets stored in a central database. The management of this
database is the task of a different agent. This means that creating a global
map is at least one agent-to-agent interaction. There is also a general
supervising agent that can tell the search robots where to go in the maze so
that exploration is optimized and robots don't explore the corridors that have
already been explored by other agents. This supervising agent can be just focus
on this task, but it can also be a stricter manager which handles most of the
communication between different agents, especially between the robot agents and
any other agents. This means that this managing agent ties all the different
services together in a single monolithic agent. This is the system that was
used in \cite{intframe}.

We plan to compare the usage of a monolithic agent versus the distributed
system. In the distributed system the robot agents can communicate directly
with the agents that communicate with web services. In this case the supervisor
will do the minimum amount necessary to create a global plan for the robotic
agents but these will have to figure out the details and communicate with
services themselves. We hope that this will remove the single point of failure
that a monolithic agent has.